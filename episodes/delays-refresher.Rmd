---
title: 'Introduction to outbreak analytics'
teaching: 10
exercises: 2
---

:::::::::::::::::::::::::::::::::::::: questions 

- How to calculate the _naive_ case fatality risk (CFR)?
- How to visualize transmission from line list data?
- How to calculate delays from line list data?
- How to fit a probability distribution to delays?

::::::::::::::::::::::::::::::::::::::::::::::::

::::::::::::::::::::::::::::::::::::: objectives

- Use the pipe operator `%>%` to structure sequences of data operations left-to-right.
- Count observations in each group using `count()`.
- Pivot data from wide-to-long or long-to-wide using `pivot_*`.
- Create new columns that are functions of existing variables using `mutate()`.
- Keep or drop columns by their names using `select()`.
- Keep rows that match a condition using `filter()`.
- Extract a single column using `pull()`.
- Create graphics declaratively using `{ggplot2}`.

::::::::::::::::::::::::::::::::::::::::::::::::

:::::::::: instructor

Useful concepts maps to teach this episode are

- <https://github.com/rstudio/concept-maps?tab=readme-ov-file#dplyr>
- <https://github.com/rstudio/concept-maps?tab=readme-ov-file#pipe-operator>
- <https://github.com/rstudio/concept-maps?tab=readme-ov-file#pivoting>

::::::::::

:::::::::: prereq

**Setup an RStudio project and folder**

- Create an RStudio project. If needed, follow this [how-to guide on "Hello RStudio Projects"](https://docs.posit.co/ide/user/ide/get-started/#hello-rstudio-projects) to create one.
- Inside the RStudio project, create the `data/` folder.
- Inside the `data/` folder, save the [linelist.rds](https://epiverse-trace.github.io/tutorials/data/linelist.rds) file.

::::::::::

::::::::::::::: checklist

**RStudio projects**

The directory of an RStudio Project named, for example `training`, should look like this:

```
training/
|__ data/
|__ training.Rproj
```

**RStudio Projects** allows you to use _relative file_ paths with respect to the `R` Project, 
making your code more portable and less error-prone. 
Avoids using `setwd()` with _absolute paths_ 
like `"C:/Users/MyName/WeirdPath/training/data/file.csv"`.

:::::::::::::::

::::::::::::::: challenge

Let's starts by creating `New Quarto Document`!

1. In the RStudio IDE, go to: File > New File > Quarto Document
2. Accept the default options
3. Save the file with the name `01-report.qmd`
4. Use the `Render` button to render the file and preview the output.

<!-- - Keep using **Quarto**. Follow their Get Started tutorial: <https://quarto.org/docs/get-started/hello/rstudio.html> -->

<!-- https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1012018 -->

:::::::::::::::

## Introduction

A new Ebola Virus Disease (EVD) outbreak has been notified in a fictional country in West Africa. The Ministry of Health is coordinating the outbreak response and has contracted you as a consultant in epidemic analysis to inform the response in real-time. The available report of cases is coming from hospital admissions.

Let's start by loading the package `{dplyr}` to manipulate data, `{tidyr}` to rearrange it, and `{here}` to write file paths within your RStudio project. We'll use the pipe `%>%` to connect some of their functions, including others from the package `{ggplot2}`, so let's call to the package `{tidyverse}` that loads them all:

```{r,eval=TRUE,message=FALSE,warning=FALSE}
# Load packages
library(tidyverse) # loads dplyr, tidyr and ggplot2
```

## Explore data

For the purpose of this episode, we will read a pre-cleaned line list data. Following episodes will tackle how to solve cleaning tasks.

```{r,eval=FALSE,echo=TRUE,message=FALSE}
# Read data
# e.g.: if path to file is data/linelist.rds then:
cases <- read_rds(
  here::here("data", "linelist.rds")
)
```

```{r,eval=TRUE,echo=FALSE,message=FALSE}
# Read data
cases <- read_rds(
  file.path("data", "linelist.rds")
)
```

:::::::::::::::::::: checklist

**Why should we use the {here} package?**

The `{here}` package is designed to simplify file referencing in R projects by providing a reliable way to construct file paths relative to the project root. The main reason to use it is **Cross-Environment Compatibility**.

It works across different operating systems (Windows, Mac, Linux) without needing to adjust file paths. 

- On Windows, paths are written using backslashes ( `\` ) as the separator between folder names: `"data\raw-data\file.csv"` 
- On Unix based operating system such as macOS or Linux the forward slash ( `/` ) is used as the path separator: `"data/raw-data/file.csv"`

The `{here}` package is ideal for adding one more layer of reproducibility to your work. If you are interested in reproducibility, we invite you to [read this tutorial to increase the openess, sustainability, and reproducibility of your epidemic analysis with R](https://epiverse-trace.github.io/research-compendium/)

::::::::::::::::::::

```{r, message=FALSE}
# Print line list data
cases
```

:::::::::::::: discussion

Take some time to look at the data and structure here.

- Are the data and format similar to line lists that you have seen in the past?
- If you were part of the outbreak investigation team, what other information might you want to collect?

::::::::::::::

:::::::::::: instructor

The information to collect will depend on the questions we need to give a response.

At the beginning of an outbreak, we need data to give a response to questions like:

- How fast does an epidemic grow?
- What is the risk of death?
- How many cases can I expect in the coming days?

Informative indicators are:

- growth rate, reproduction number.
- case fatality risk, hospitalization fatality risk.
- projection or forecast of cases.

Useful data are:

- date of onset, date of death.
- delays from infection to onset, from onset to death.
- percentage of observations detected by surveillance system.
- subject characteristics to stratify the analysis by person, place, time.

::::::::::::

You may notice that there are **missing** entries.

An important step in analysis is to identify any mistakes in data entry. The package `{cleanepi}` includes one function called `scan_data()` to get the percentage of missing observations per variable:

```{r}
cases %>%
  cleanepi::scan_data()
```

:::::::::::: discussion

Why do we have more missings on date of infection or date of outcome?

::::::::::::

::::::::::::: instructor

- date of infection: mostly unknown, depended on limited coverage of contact tracing or outbreak research, and sensitive to recall bias from subjects.
- date of outcome: reporting delay

:::::::::::::

::::::::::::: spoiler

We can also explore missing data with summary a visualization:

```{r}
cases %>%
  visdat::vis_miss()
```

:::::::::::::

::::::::::::::::::: checklist

**The double-colon**

The double-colon `::` in R let you call a specific function from a package without loading the entire package into the current environment. 

For example, `dplyr::filter(data, condition)` uses `filter()` from the `{dplyr}` package.

This help us remember package functions and avoid namespace conflicts.

:::::::::::::::::::

## Calculate severity

A frequent indicator for severity is the case fatality risk (CFR). 

CFR is defined as the conditional probability of death given confirmed diagnosis, calculated as the cumulative number of deaths from an infectious disease over the number of confirmed diagnosed cases.

We can use the function `dplyr::count()` to count the observations in each group of the variable `outcome`:

```{r}
cases %>%
  dplyr::count(outcome)
```

:::::::::::: discussion

Report:

- What to do with cases whose outcome is `NA`?

- Should we consider missing outcomes to calculate the CFR?

::::::::::::

:::::::::::: instructor

CFR estimation is sensitive to:

- **Right-censoring bias**. If we include observations with unknown final status we can underestimate the true CFR.

- **Selection bias**. At the beginning of an outbreak, given that health systems collect most clinically severe cases, an early estimate of the CFR can overestimate the true CFR. 

::::::::::::

To calculate the CFR we can add more functions using the pipe `%>%` and structure sequences of data operations left-to-right.

From the `cases` object we will use:

- `dplyr::count()` to count the observations in each group of the variable `outcome`,
- `tidyr::pivot_wider()` to pivot the data long-to-wide with names from `outcome` and values from `n` columns,
- `cleanepi::standardize_column_names()` to standardize column names,
- `dplyr::mutate()` to create one new column `cases_known_outcome` as a function of existing variables `death` and `recover`.

```{r}
# calculate the number of cases with known outcome
cases %>%
  dplyr::count(outcome) %>%
  tidyr::pivot_wider(names_from = outcome, values_from = n) %>%
  cleanepi::standardize_column_names() %>%
  dplyr::mutate(cases_known_outcome = death + recover)
```

This way of writing almost look like writing a recipe!

:::::::::::: challenge

Calculate the CFR as the division of the number of **deaths** among **known outcomes**. Do this by adding one more pipe `%>%` in the last code chunk. 

Report:

- What is the value of the CFR?

:::::::::::: hint

You can use the column names of variables to create one more column:

```{r,eval=FALSE,echo=TRUE}
# calculate the naive CFR
cases %>%
  count(outcome) %>%
  pivot_wider(names_from = outcome, values_from = n) %>%
  cleanepi::standardize_column_names() %>%
  mutate(cases_known_outcome = death + recover) %>%
  mutate(cfr = ... / ...) # replace the ... spaces
```

::::::::::::

:::::::::::: solution

```{r}
# calculate the naive CFR
cases %>%
  dplyr::count(outcome) %>%
  tidyr::pivot_wider(names_from = outcome, values_from = n) %>%
  cleanepi::standardize_column_names() %>%
  dplyr::mutate(cases_known_outcome = death + recover) %>%
  dplyr::mutate(cfr = death / cases_known_outcome)
```

This calculation is _naive_ because it tends to yield a biased and mostly underestimated CFR due to the time-delay from onset to death, only stabilising at the later stages of the outbreak.

Now, as a comparison, how much a CFR estimate changes if we include unknown outcomes in the denominator?

::::::::::::

:::::::::::: solution

```{r}
# underestimate the naive CFR
cases %>%
  dplyr::count(outcome) %>%
  tidyr::pivot_wider(names_from = outcome, values_from = n) %>%
  cleanepi::standardize_column_names() %>%
  dplyr::mutate(cfr = death / (death + recover + na))
```

Considering unknown outcomes underestimates the _naive_ CFR calculation.

::::::::::::

::::::::::::

However, in average, how much time it would take to know the outcomes of those cases? For this we can calculate **delays**!

## Calculate delays

The time between sequence of dated events can vary between subjects. For example, we would expect the date of infection to always be before the date of symptom onset, and the later always before the date of hospitalization.

```{r,echo=FALSE,eval=TRUE}
# demo code not to run by learner
set.seed(99)

cases_select <- cases %>%
  dplyr::slice_sample(n = 30) %>%
  dplyr::arrange(date_of_onset) %>%
  dplyr::mutate(case_id = fct_inorder(case_id)) %>%
  # slice(10:40) %>%
  dplyr::select(
    case_id,
    date_of_onset,
    date_of_hospitalisation
  )

cases_long <- cases_select %>%
  tidyr::pivot_longer(
    cols = -case_id,
    names_to = "date_type",
    values_to = "date"
  ) %>%
  dplyr::mutate(date_type = fct_relevel(date_type, "date_of_onset"))

ggplot() +
  geom_point(
    data = cases_long,
    aes(x = date, y = case_id, color = date_type),
    alpha = 0.5, size = 3
  ) +
  geom_segment(
    data = cases_select,
    aes(x = date_of_onset, y = case_id,
        xend = date_of_hospitalisation, yend = case_id),
    color = "grey"
  ) +
  colorspace::scale_color_discrete_diverging(palette = "Blue-Red 2")
```

Given that the date of hospitalization means the date of report, we can calculate the **reporting delay** from this line list data.

From the `cases` object we will use:

- `dplyr::select()` to keep columns using their names,
- `dplyr::mutate()` to create one new column `reporting_delay` as a function of existing variables `date_of_hospitalisation` and `date_of_onset`,
- `ggplot()` to declare the input data frame for a graphic,
- `aes()` to describe how variables in the data are mapped to visual properties (aesthetics) of `geoms`,
- `geom_histogram()` to visualise the distribution of a single continuous variable by dividing the x axis into `bins` and counting the number of observations in each `bin`.

```{r,warning=FALSE,message=FALSE}
cases %>%
  dplyr::select(case_id, date_of_onset, date_of_hospitalisation) %>%
  dplyr::mutate(reporting_delay = date_of_hospitalisation - date_of_onset) %>%
  ggplot(aes(x = reporting_delay)) +
  geom_histogram(binwidth = 1)
```


::::::::::::::::: challenge

To calculate a _delay-adjusted_ CFR, we need to assume a known the delay from onset to death.

Using the `cases` object:

- Calculate and visualize the delay from onset to death.

::::::::::::: hint

We can keep the rows that match a given logical statement, like `outcome == "Death"`, using the function `dplyr::filter()`:

```{r,eval=FALSE,echo=TRUE}
cases %>%
  dplyr::filter(outcome == "Death")
```

:::::::::::::

::::::::::::: solution

```{r,warning=FALSE,message=FALSE}
cases %>%
  dplyr::select(case_id, date_of_onset, date_of_outcome, outcome) %>%
  dplyr::filter(outcome == "Death") %>%
  dplyr::mutate(delay_onset_death = date_of_outcome - date_of_onset) %>%
  ggplot(aes(x = delay_onset_death)) +
  geom_histogram(binwidth = 1)
```

Wait! Is is consistent to have negative time delays from primary to secondary observations, i.e., from date of onset to date of death?

In the next episode we will learn how to check sequence of dated-events and more inconsistencies!

But, how would you keep the rows with negative delay values? Try this out.

:::::::::::::

:::::::::::: solution

We can use `dplyr::filter()` again to identify the inconsistent observations:

```{r}
cases %>%
  dplyr::select(case_id, date_of_onset, date_of_outcome, outcome) %>%
  dplyr::filter(outcome == "Death") %>%
  dplyr::mutate(delay_onset_death = date_of_outcome - date_of_onset) %>%
  dplyr::filter(delay_onset_death < 1)
```

::::::::::::

:::::::::::::::::


## Visualize transmission

- Incidence curve

aggregate the date by intervals of 7 days

```{r}

# transmission ------------------------------------------------------------

# incidence curve ---------------------------------------------------------

cases %>%
  ggplot(aes(x = date_of_onset)) +
  geom_histogram(binwidth = 7)

# what transmission indicator can we estimate from the incidence curve? ---

#' the growth rate! by fitting a linear model
#' more on that on DAY 3-4

# what is the name of the delay from infection to symptom onset? ----------
```

However, as seen before, the date of onset of symptoms is a delayed measurement with respect to the date of infection.

On the last date of hospitalisation, which is the date when the case is registered in the data collection system, the last date of onset of symptoms happened some days ago:

```{r}
cases %>%
  dplyr::summarise(
    max(date_of_onset),
    max(date_of_hospitalisation)
  )
```


There is an average time delay between the date of infection, date of onset, date of hospitalisation, and date of outcome.

```{r,eval=TRUE,echo=FALSE,warning=FALSE,message=FALSE}
cases %>%
  dplyr::mutate(
    delayed = dplyr::case_when(
      # date_of_hospitalisation < max(date_of_hospitalisation)-(7 * 5) ~
      #   "5 weeks before",
      # date_of_hospitalisation < max(date_of_hospitalisation)-(7 * 4) ~
      #   "4 weeks before",
      date_of_hospitalisation < max(date_of_hospitalisation) - (7 * 2) ~
        "2 week before",
      TRUE ~ "Today"
    )
  ) %>%
  mutate(
    delayed = forcats::fct_relevel(delayed, "Today")
  ) %>%
  ggplot(aes(date_of_onset, fill = delayed)) +
  geom_histogram(binwidth = 7) +
  labs(fill = "Observed cases")
```

In order to account for these time delays when estimating indicators of severity or transmission, we need to input delays as **Probability Distributions**!

## Fit a probability distribution to delays

::::::::::::::::::: prereq

**Watch** one 5-minute video refresher on probability distributions:

- StatQuest with Josh Starmer (2017) 
**The Main Ideas behind Probability Distributions**, YouTube. 
Available at: <https://www.youtube.com/watch?v=oI3hZJqXJuc&t> 
<!--(Accessed: 30 October 2024).-->

:::::::::::::::::::



```{r,warning=FALSE,message=FALSE}
cases %>%
  dplyr::select(case_id, date_of_infection, date_of_onset) %>%
  dplyr::mutate(incubation_period = date_of_onset - date_of_infection) %>%
  ggplot(aes(x = incubation_period)) +
  geom_histogram(binwidth = 1)
```


```{r}
cases %>%
  dplyr::select(case_id, date_of_infection, date_of_onset) %>%
  dplyr::mutate(incubation_period = date_of_onset - date_of_infection) %>%
  dplyr::mutate(incubation_period_num = as.numeric(incubation_period)) %>%
  dplyr::filter(!is.na(incubation_period_num)) %>%
  dplyr::pull(incubation_period_num) %>%
  fitdistrplus::fitdist(distr = "lnorm") # try: summary and plot

#' explore the
#' https://ben18785.shinyapps.io/distribution-zoo/
#' for gamma, weibull, lnorm parameters
```

::::::::::::::: callout

**The dollar sign `$` can `pull()`**

```{r}
cases_delay <- cases %>%
  dplyr::select(case_id, date_of_infection, date_of_onset) %>%
  dplyr::mutate(incubation_period = date_of_onset - date_of_infection) %>%
  dplyr::mutate(incubation_period_num = as.numeric(incubation_period)) %>%
  dplyr::filter(!is.na(incubation_period_num))
```

```{r}
cases_delay %>% dplyr::pull(incubation_period_num)
```

Try this yourself:

```{r,eval=FALSE,echo=TRUE}
cases_delay$incubation_period_num
```

:::::::::::::::

::::::::::::::: callout

**The dollar sign `$` can `pluck()`**

```{r}
incubation_period_fit <- cases %>%
  dplyr::select(case_id, date_of_infection, date_of_onset) %>%
  dplyr::mutate(incubation_period = date_of_onset - date_of_infection) %>%
  dplyr::mutate(incubation_period_num = as.numeric(incubation_period)) %>%
  dplyr::filter(!is.na(incubation_period_num)) %>%
  dplyr::pull(incubation_period_num) %>%
  fitdistrplus::fitdist(distr = "lnorm")
```

```{r}
incubation_period_fit %>% purrr::pluck("estimate")
```

Try this yourself:

```{r,eval=FALSE,echo=TRUE}
incubation_period_fit$estimate
```

But, how do you access to the specific parameter?

:::::::::::::::

:::::::::::::::::::::::::::::: testimonial

**A code completion tip**

If we write the **square brackets** `[]` next to the object `incubation_period_fit$estimate[]`, within `[]` we can use the 
Tab key <kbd>↹</kbd> 
for [code completion feature](https://support.posit.co/hc/en-us/articles/205273297-Code-Completion-in-the-RStudio-IDE) 

This gives quick access to `incubation_period_fit$estimate["meanlog"]` and `incubation_period_fit$estimate["sdlog"]`. 

We invite you to try this out in code chunks and the R console!

::::::::::::::::::::::::::::::

## Why to fit a probability distribution to data?

```{r}
# why to fit a distribution to observed data? -----------------------------

#' the time difference from date infection and date symptom onset
#' give us the incubation period
#'
#' steps
#' - calculate the time difference
#' - plot
#' - fit a probability distribution (obtain distribution parameters)
#' - do inferences
#'
#' from the incubation period distribution
#' we can infer the length of active monitoring or quarantine
#' example
#' within what time frame do 99% of individuals
#' exhibiting Ebola symptoms exhibit them after infection?

#' review probability functions
qlnorm(p = 0.99, meanlog = 1.995979, sdlog = 0.776226)

#' reference: https://pubmed.ncbi.nlm.nih.gov/32150748/
#' Lauer, 2020
#' The Incubation Period of Coronavirus Disease 2019 (COVID-19)
#' From Publicly Reported Confirmed Cases: Estimation and Application
```

::::::::::::::: testimonial

**What to do if we do not have enough data?**

At the beginning of an outbreak, limited data or resources exist to estimate delays accounting for its biases. Until we have more appropriate data for the specific disease and region for the ongoing outbreak, we can reuse delays from past outbreaks from the same pathogens or close in its phylogeny, independent of the area of origin.

In the next tutorial episodes, we will:

- Access and analyse common epidemiological parameters from open-source literature search databases.
- Estimate key transmission metrics, such as the reproduction number, from case or death data, adjusting for incubation period and reporting delays.
- Estimate the case fatality risk (CFR) from individual-level and aggregated incidence case and death data, adjusting for delays between onset of symptoms and disease outcome.

:::::::::::::::

```{r}
# challenge ----------------------------------------------------------------

# use epidemiological times figure TRACE LAC ------------------------------

#' PAHO figure
#' if we have the serial interval
#' we can make inferences about the window for contact tracing
#' expand the number of pre-days to include more backward contacts
```

::::::::::::::: challenge

Let's create **reproducible examples (`reprex`)**. A reprex help us to communicate our coding problems with software developers. Explore this Applied Epi entry: <https://community.appliedepi.org/t/how-to-make-a-reproducible-r-code-example/167>

Create a `reprex` with your answer:

- What is the value of the CFR from the data set in the chuck below?

```{r}
outbreaks::ebola_sim_clean %>% 
  pluck("linelist") %>% 
  as_tibble()
```

:::::::::::::::

::::::::::::::::::::::::::::::::::::: keypoints 

- Use packages from the `tidyverse` like `{dplyr}`, `{tidyr}`, and `{ggplot2}` for exploratory data analysis.
- Epidemiological delays conditions the estimation of indicators for severity or transmission. 
- Fit probability distribution to delays to make inferences from them for decision making.

::::::::::::::::::::::::::::::::::::::::::::::::

### References

- Cori, A. et al. (2019) Real-time outbreak analysis: Ebola as a case study - part 1 · Recon Learn, RECON learn. Available at: https://www.reconlearn.org/post/real-time-response-1 (Accessed: 06 November 2024).
